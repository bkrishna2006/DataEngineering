Code re-factoring

1. The following are the Project's directories

<Directory>/GenData		-->  Contains data generated by the programs in this Project.
<Directory>/RawData		-->  Contains Raw data ingested from external sources
<Directory>/RefData		-->  Contains external Reference data relevant for the project.
<Directory>/SampleData		-->  Contains samples of raw data created from Original Raw data.	
<Directory>/Scripts		-->  Contains executable programs.	

2. Raw data is downloaded once and stored in <Directory>/RawData.  The profanity words list is also downloaded once and stored in <Directory>/RefData.

3. Programs are modularized for the below functions and the program names are given in brackets. 
1. Data Engineering (DataEngineering.R)
	1. Data Ingestion
	2. Data Exploration
		1. Gathering statistics
		2. Data Sampling
<Note> This program, based on the sampling size decided, creates the sample files for further steps.
2. Text Mining
	1. Data cleansing
		1. Creating Corpus and Removing white spaces
		2. Removing Punctuations
		3. Removing numbers
		4. Convert all to lowercase
		4. Removing stopwords 
		5. Removing profanity words
		6. Custom cleansing	
			1. Address www. and .com 
			2. Removing non-ASCII characters
		7. Stemming (Optional - Stemming is found to lower the accuracy of predictions for obvious reasons.)
	2. Data Exploration
		1. Preparing TDMs (Term Document Matrix)	
		2. Word Clouds
		3. Histograms	
<Note> This program, creates a clean Document Corpus using tm package and saves it, for use down the line.
	
3. n-grams
	1. Preparing n-grams
		1. Tokenization
		2. Preparing DFMs (Document Frequency Matrix)
		3. Preparing n-grams, n-gram frequency table
		4. Deciding on Quantity of unique n-grams required for prediction.
		5. Preparing n-gram Dataframes. 
3  Text Prediction Modelling.
	1. Preparing unique n-gram frequency and probability table for each of the ngrams
	2. Drop the n-grams where the probability is extremely low (close to 0)
	3. Split each of the unique n-grams into "n-1 gram" and "predicted next word"
	4. Combine all n-gram tables containing n-1grams, predicted-next-word, freq & prob into a single look-up table.
<Note> This program, creates a All-gram look up table, for predictions.
4. Shiny App creation
5. Integration
		